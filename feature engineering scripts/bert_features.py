import pandas as pd
import numpy as np
import torch
from transformers import BertTokenizer, BertModel
from tqdm import tqdm
import warnings

warnings.filterwarnings('ignore')

# ============================================================
# 1. é…ç½®
# ============================================================
ORIGINAL_DATA_PATH = r'F:\å·¥ä½œ\ä¸Šå¤§\NLP\test2\initial datasets\labeled_data.csv'
OUTPUT_PATH = r'F:\å·¥ä½œ\ä¸Šå¤§\NLP\test2\feature datasets\bert_features.csv'

# é€‰æ‹© BERT æ¨¡å‹ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦æ›´æ¢ï¼‰
MODEL_NAME = 'bert-base-uncased'  # æˆ– 'bert-large-uncased'
MAX_LENGTH = 128  # æ¨æ–‡æœ€å¤§é•¿åº¦
BATCH_SIZE = 16  # æ‰¹å¤„ç†å¤§å°ï¼ˆæ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼‰

# ============================================================
# 2. æ£€æŸ¥ GPU å¯ç”¨æ€§
# ============================================================
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")
if device.type == 'cuda':
    print(f"   GPU: {torch.cuda.get_device_name(0)}")

# ============================================================
# 3. åŠ è½½ BERT æ¨¡å‹å’Œåˆ†è¯å™¨
# ============================================================
print("\n" + "=" * 70)
print("æ­¥éª¤ 1: åŠ è½½ BERT æ¨¡å‹")
print("=" * 70)

tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)
model = BertModel.from_pretrained(MODEL_NAME)
model.to(device)
model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼

print(f"âœ… BERT æ¨¡å‹åŠ è½½å®Œæˆ: {MODEL_NAME}")

# ============================================================
# 4. åŠ è½½æ•°æ®
# ============================================================
print("\n" + "=" * 70)
print("æ­¥éª¤ 2: åŠ è½½åŸå§‹æ•°æ®")
print("=" * 70)

try:
    data = pd.read_csv(ORIGINAL_DATA_PATH, encoding='utf-8')
except:
    data = pd.read_csv(ORIGINAL_DATA_PATH, encoding='ISO-8859-1')

if 'index' not in data.columns:
    data['index'] = range(len(data))

print(f"âœ… åŠ è½½ {len(data)} æ¡æ¨æ–‡")


# ============================================================
# 5. å®šä¹‰ BERT ç‰¹å¾æå–å‡½æ•°
# ============================================================
def extract_bert_features(texts, batch_size=BATCH_SIZE):
    """
    æ‰¹é‡æå– BERT ç‰¹å¾

    å‚æ•°:
        texts: æ–‡æœ¬åˆ—è¡¨
        batch_size: æ‰¹å¤„ç†å¤§å°

    è¿”å›:
        numpy array: shape (n_samples, 768)
    """
    all_embeddings = []

    # åˆ†æ‰¹å¤„ç†
    for i in tqdm(range(0, len(texts), batch_size), desc="æå– BERT ç‰¹å¾"):
        batch_texts = texts[i:i + batch_size]

        # åˆ†è¯å’Œç¼–ç 
        encoded = tokenizer(
            batch_texts,
            padding=True,
            truncation=True,
            max_length=MAX_LENGTH,
            return_tensors='pt'
        )

        # å°†æ•°æ®ç§»åˆ° GPU
        input_ids = encoded['input_ids'].to(device)
        attention_mask = encoded['attention_mask'].to(device)

        # æå–ç‰¹å¾ï¼ˆä¸è®¡ç®—æ¢¯åº¦ï¼‰
        with torch.no_grad():
            outputs = model(input_ids=input_ids, attention_mask=attention_mask)

            # ä½¿ç”¨ [CLS] token çš„è¾“å‡ºä½œä¸ºå¥å­è¡¨ç¤º
            # outputs.last_hidden_state: (batch_size, seq_len, hidden_size)
            # å–ç¬¬ä¸€ä¸ª tokenï¼ˆ[CLS]ï¼‰çš„è¡¨ç¤º
            cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()

            all_embeddings.append(cls_embeddings)

    # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡
    return np.vstack(all_embeddings)


# ============================================================
# 6. æå– BERT ç‰¹å¾
# ============================================================
print("\n" + "=" * 70)
print("æ­¥éª¤ 3: æå– BERT ç‰¹å¾")
print("=" * 70)

tweets = data['tweet'].fillna('').tolist()
bert_embeddings = extract_bert_features(tweets)

print(f"âœ… BERT ç‰¹å¾ç»´åº¦: {bert_embeddings.shape}")
print(f"   æ ·æœ¬æ•°: {bert_embeddings.shape[0]}")
print(f"   ç‰¹å¾ç»´åº¦: {bert_embeddings.shape[1]}")

# ============================================================
# 7. åˆ›å»º DataFrame å¹¶æ·»åŠ å‰ç¼€
# ============================================================
print("\n" + "=" * 70)
print("æ­¥éª¤ 4: åˆ›å»ºç‰¹å¾ DataFrame")
print("=" * 70)

# åˆ›å»ºåˆ—åï¼šbert:0, bert:1, ..., bert:767
bert_columns = [f'bert:{i}' for i in range(bert_embeddings.shape[1])]
bert_df = pd.DataFrame(bert_embeddings, columns=bert_columns)

# æ·»åŠ  index åˆ—ç”¨äºåˆå¹¶
bert_df['index'] = data['index'].values

print(f"âœ… DataFrame åˆ›å»ºå®Œæˆ: {bert_df.shape}")

# ============================================================
# 8. ä¿å­˜ç‰¹å¾æ–‡ä»¶
# ============================================================
print("\n" + "=" * 70)
print("æ­¥éª¤ 5: ä¿å­˜ BERT ç‰¹å¾")
print("=" * 70)

bert_df.to_csv(OUTPUT_PATH, index=False)
print(f"âœ… BERT ç‰¹å¾å·²ä¿å­˜åˆ°: {OUTPUT_PATH}")
print(f"âœ… åŒ…å«çš„åˆ—: index + {len(bert_columns)} ä¸ª BERT ç‰¹å¾")

# ============================================================
# 9. ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯
# ============================================================
print("\n" + "=" * 70)
print("ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯")
print("=" * 70)

print(f"\nğŸ“Š BERT ç‰¹å¾ç»Ÿè®¡:")
print(f"  - å¹³å‡å€¼: {bert_embeddings.mean():.4f}")
print(f"  - æ ‡å‡†å·®: {bert_embeddings.std():.4f}")
print(f"  - æœ€å°å€¼: {bert_embeddings.min():.4f}")
print(f"  - æœ€å¤§å€¼: {bert_embeddings.max():.4f}")

print("\n" + "=" * 70)
print("ğŸ‰ BERT ç‰¹å¾æå–å®Œæˆï¼")
print("=" * 70)
print("\nä¸‹ä¸€æ­¥:")
print("  1. è¿è¡Œ hate_speech_detection.py è®­ç»ƒæ¨¡å‹")
print("  2. æ¨¡å‹ä¼šè‡ªåŠ¨åŠ è½½ BERT ç‰¹å¾è¿›è¡Œè®­ç»ƒ")